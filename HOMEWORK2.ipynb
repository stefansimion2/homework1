{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fe4acff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a1819a",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048dbfc1",
   "metadata": {},
   "source": [
    "# LINK TO CHATGPT CONVERSATION IN VERY LAST CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257939a4",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1854885f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>species</th>\n",
       "      <th>birthday</th>\n",
       "      <th>personality</th>\n",
       "      <th>song</th>\n",
       "      <th>phrase</th>\n",
       "      <th>full_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>admiral</td>\n",
       "      <td>Admiral</td>\n",
       "      <td>male</td>\n",
       "      <td>bird</td>\n",
       "      <td>1-27</td>\n",
       "      <td>cranky</td>\n",
       "      <td>Steep Hill</td>\n",
       "      <td>aye aye</td>\n",
       "      <td>villager-admiral</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>agent-s</td>\n",
       "      <td>Agent S</td>\n",
       "      <td>female</td>\n",
       "      <td>squirrel</td>\n",
       "      <td>7-2</td>\n",
       "      <td>peppy</td>\n",
       "      <td>DJ K.K.</td>\n",
       "      <td>sidekick</td>\n",
       "      <td>villager-agent-s</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>agnes</td>\n",
       "      <td>Agnes</td>\n",
       "      <td>female</td>\n",
       "      <td>pig</td>\n",
       "      <td>4-21</td>\n",
       "      <td>uchi</td>\n",
       "      <td>K.K. House</td>\n",
       "      <td>snuffle</td>\n",
       "      <td>villager-agnes</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>al</td>\n",
       "      <td>Al</td>\n",
       "      <td>male</td>\n",
       "      <td>gorilla</td>\n",
       "      <td>10-18</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Steep Hill</td>\n",
       "      <td>Ayyeeee</td>\n",
       "      <td>villager-al</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>alfonso</td>\n",
       "      <td>Alfonso</td>\n",
       "      <td>male</td>\n",
       "      <td>alligator</td>\n",
       "      <td>6-9</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Forest Life</td>\n",
       "      <td>it'sa me</td>\n",
       "      <td>villager-alfonso</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>475</td>\n",
       "      <td>winnie</td>\n",
       "      <td>Winnie</td>\n",
       "      <td>female</td>\n",
       "      <td>horse</td>\n",
       "      <td>1-31</td>\n",
       "      <td>peppy</td>\n",
       "      <td>My Place</td>\n",
       "      <td>hay-OK</td>\n",
       "      <td>villager-winnie</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>477</td>\n",
       "      <td>wolfgang</td>\n",
       "      <td>Wolfgang</td>\n",
       "      <td>male</td>\n",
       "      <td>wolf</td>\n",
       "      <td>11-25</td>\n",
       "      <td>cranky</td>\n",
       "      <td>K.K. Song</td>\n",
       "      <td>snarrrl</td>\n",
       "      <td>villager-wolfgang</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>480</td>\n",
       "      <td>yuka</td>\n",
       "      <td>Yuka</td>\n",
       "      <td>female</td>\n",
       "      <td>koala</td>\n",
       "      <td>7-20</td>\n",
       "      <td>snooty</td>\n",
       "      <td>Soulful K.K.</td>\n",
       "      <td>tsk tsk</td>\n",
       "      <td>villager-yuka</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>481</td>\n",
       "      <td>zell</td>\n",
       "      <td>Zell</td>\n",
       "      <td>male</td>\n",
       "      <td>deer</td>\n",
       "      <td>6-7</td>\n",
       "      <td>smug</td>\n",
       "      <td>K.K. D&amp;B</td>\n",
       "      <td>pronk</td>\n",
       "      <td>villager-zell</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>483</td>\n",
       "      <td>zucker</td>\n",
       "      <td>Zucker</td>\n",
       "      <td>male</td>\n",
       "      <td>octopus</td>\n",
       "      <td>3-8</td>\n",
       "      <td>lazy</td>\n",
       "      <td>Spring Blossoms</td>\n",
       "      <td>bloop</td>\n",
       "      <td>villager-zucker</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_n        id      name  gender    species birthday personality  \\\n",
       "0        2   admiral   Admiral    male       bird     1-27      cranky   \n",
       "1        3   agent-s   Agent S  female   squirrel      7-2       peppy   \n",
       "2        4     agnes     Agnes  female        pig     4-21        uchi   \n",
       "3        6        al        Al    male    gorilla    10-18        lazy   \n",
       "4        7   alfonso   Alfonso    male  alligator      6-9        lazy   \n",
       "..     ...       ...       ...     ...        ...      ...         ...   \n",
       "386    475    winnie    Winnie  female      horse     1-31       peppy   \n",
       "387    477  wolfgang  Wolfgang    male       wolf    11-25      cranky   \n",
       "388    480      yuka      Yuka  female      koala     7-20      snooty   \n",
       "389    481      zell      Zell    male       deer      6-7        smug   \n",
       "390    483    zucker    Zucker    male    octopus      3-8        lazy   \n",
       "\n",
       "                song    phrase            full_id  \\\n",
       "0         Steep Hill   aye aye   villager-admiral   \n",
       "1            DJ K.K.  sidekick   villager-agent-s   \n",
       "2         K.K. House   snuffle     villager-agnes   \n",
       "3         Steep Hill   Ayyeeee        villager-al   \n",
       "4        Forest Life  it'sa me   villager-alfonso   \n",
       "..               ...       ...                ...   \n",
       "386         My Place    hay-OK    villager-winnie   \n",
       "387        K.K. Song   snarrrl  villager-wolfgang   \n",
       "388     Soulful K.K.   tsk tsk      villager-yuka   \n",
       "389         K.K. D&B     pronk      villager-zell   \n",
       "390  Spring Blossoms     bloop    villager-zucker   \n",
       "\n",
       "                                                   url  \n",
       "0    https://villagerdb.com/images/villagers/thumb/...  \n",
       "1    https://villagerdb.com/images/villagers/thumb/...  \n",
       "2    https://villagerdb.com/images/villagers/thumb/...  \n",
       "3    https://villagerdb.com/images/villagers/thumb/...  \n",
       "4    https://villagerdb.com/images/villagers/thumb/...  \n",
       "..                                                 ...  \n",
       "386  https://villagerdb.com/images/villagers/thumb/...  \n",
       "387  https://villagerdb.com/images/villagers/thumb/...  \n",
       "388  https://villagerdb.com/images/villagers/thumb/...  \n",
       "389  https://villagerdb.com/images/villagers/thumb/...  \n",
       "390  https://villagerdb.com/images/villagers/thumb/...  \n",
       "\n",
       "[391 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd486bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 391 rows and 11 columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_data = pd.read_csv(url)\n",
    "\n",
    "# Get the shape of the dataset (rows, columns)\n",
    "rows, columns = villagers_data.shape\n",
    "\n",
    "# Print the number of rows and columns\n",
    "print(f\"The dataset has {rows} rows and {columns} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2903a03b",
   "metadata": {},
   "source": [
    "# Question 2.2\n",
    "\n",
    "### observation \n",
    "each row represents an observation of a data point, in my case of using villagers you can read from left to right on each row to find specific unique characterization of each villager\n",
    "\n",
    "### Variable\n",
    "the variables are represented in the columns in the dataset, each column's header in this case give different characterization to villagers (gender, birthday, personality, etc...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5d34dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Rows of the Dataset:\n",
      "--------------------------------------------------\n",
      "   row_n       id     name  gender    species birthday personality  \\\n",
      "0      2  admiral  Admiral    male       bird     1-27      cranky   \n",
      "1      3  agent-s  Agent S  female   squirrel      7-2       peppy   \n",
      "2      4    agnes    Agnes  female        pig     4-21        uchi   \n",
      "3      6       al       Al    male    gorilla    10-18        lazy   \n",
      "4      7  alfonso  Alfonso    male  alligator      6-9        lazy   \n",
      "\n",
      "          song    phrase           full_id  \\\n",
      "0   Steep Hill   aye aye  villager-admiral   \n",
      "1      DJ K.K.  sidekick  villager-agent-s   \n",
      "2   K.K. House   snuffle    villager-agnes   \n",
      "3   Steep Hill   Ayyeeee       villager-al   \n",
      "4  Forest Life  it'sa me  villager-alfonso   \n",
      "\n",
      "                                                 url  \n",
      "0  https://villagerdb.com/images/villagers/thumb/...  \n",
      "1  https://villagerdb.com/images/villagers/thumb/...  \n",
      "2  https://villagerdb.com/images/villagers/thumb/...  \n",
      "3  https://villagerdb.com/images/villagers/thumb/...  \n",
      "4  https://villagerdb.com/images/villagers/thumb/...  \n",
      "\n",
      "\n",
      "Dataset Information:\n",
      "--------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        391 non-null    int64 \n",
      " 1   id           390 non-null    object\n",
      " 2   name         391 non-null    object\n",
      " 3   gender       391 non-null    object\n",
      " 4   species      391 non-null    object\n",
      " 5   birthday     391 non-null    object\n",
      " 6   personality  391 non-null    object\n",
      " 7   song         380 non-null    object\n",
      " 8   phrase       391 non-null    object\n",
      " 9   full_id      391 non-null    object\n",
      " 10  url          391 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 33.7+ KB\n",
      "\n",
      "\n",
      "Summary Statistics for Numerical Columns:\n",
      "--------------------------------------------------\n",
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "\n",
      "\n",
      "Value Counts for Categorical Columns:\n",
      "==================================================\n",
      "\n",
      "Column: row_n\n",
      "--------------------------------------------------\n",
      "row_n\n",
      "2      1\n",
      "303    1\n",
      "331    1\n",
      "330    1\n",
      "328    1\n",
      "      ..\n",
      "151    1\n",
      "150    1\n",
      "149    1\n",
      "148    1\n",
      "483    1\n",
      "Name: count, Length: 391, dtype: int64\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Column: id\n",
      "--------------------------------------------------\n",
      "id\n",
      "admiral    1\n",
      "mott       1\n",
      "paula      1\n",
      "patty      1\n",
      "pate       1\n",
      "          ..\n",
      "eloise     1\n",
      "elmer      1\n",
      "ellie      1\n",
      "elise      1\n",
      "zucker     1\n",
      "Name: count, Length: 390, dtype: int64\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Column: name\n",
      "--------------------------------------------------\n",
      "name\n",
      "Admiral    1\n",
      "Muffy      1\n",
      "Paula      1\n",
      "Patty      1\n",
      "Pate       1\n",
      "          ..\n",
      "Elvis      1\n",
      "Eloise     1\n",
      "Elmer      1\n",
      "Ellie      1\n",
      "Zucker     1\n",
      "Name: count, Length: 391, dtype: int64\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Column: gender\n",
      "--------------------------------------------------\n",
      "gender\n",
      "male      204\n",
      "female    187\n",
      "Name: count, dtype: int64\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Column: species\n",
      "--------------------------------------------------\n",
      "species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Column: birthday\n",
      "--------------------------------------------------\n",
      "birthday\n",
      "1-27     2\n",
      "12-5     2\n",
      "7-31     2\n",
      "3-26     2\n",
      "8-3      2\n",
      "        ..\n",
      "4-3      1\n",
      "10-26    1\n",
      "7-23     1\n",
      "12-8     1\n",
      "3-8      1\n",
      "Name: count, Length: 361, dtype: int64\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Column: personality\n",
      "--------------------------------------------------\n",
      "personality\n",
      "lazy      60\n",
      "normal    59\n",
      "cranky    55\n",
      "snooty    55\n",
      "jock      55\n",
      "peppy     49\n",
      "smug      34\n",
      "uchi      24\n",
      "Name: count, dtype: int64\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Column: song\n",
      "--------------------------------------------------\n",
      "song\n",
      "K.K. Country     10\n",
      "Forest Life       9\n",
      "Imperial K.K.     7\n",
      "K.K. Soul         7\n",
      "K.K. Ragtime      7\n",
      "                 ..\n",
      "Aloha K.K.        2\n",
      "Drivin'           1\n",
      "Senor K.K.        1\n",
      "K.K.  Bazaar      1\n",
      "K.K. D&B          1\n",
      "Name: count, Length: 92, dtype: int64\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Column: phrase\n",
      "--------------------------------------------------\n",
      "phrase\n",
      "wee one       2\n",
      "quacko        2\n",
      "bloop         2\n",
      "aye aye       1\n",
      "snoot         1\n",
      "             ..\n",
      "lambchop      1\n",
      "yeah buddy    1\n",
      "chow down     1\n",
      "unh-hunh      1\n",
      "pronk         1\n",
      "Name: count, Length: 388, dtype: int64\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Column: full_id\n",
      "--------------------------------------------------\n",
      "full_id\n",
      "villager-admiral    1\n",
      "villager-muffy      1\n",
      "villager-paula      1\n",
      "villager-patty      1\n",
      "villager-pate       1\n",
      "                   ..\n",
      "villager-elvis      1\n",
      "villager-eloise     1\n",
      "villager-elmer      1\n",
      "villager-ellie      1\n",
      "villager-zucker     1\n",
      "Name: count, Length: 391, dtype: int64\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Column: url\n",
      "--------------------------------------------------\n",
      "url\n",
      "https://villagerdb.com/images/villagers/thumb/admiral.98206ee.png    1\n",
      "https://villagerdb.com/images/villagers/thumb/muffy.1497c92.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/paula.563ba81.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/patty.3e17f7f.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/pate.c60838c.png       1\n",
      "                                                                    ..\n",
      "https://villagerdb.com/images/villagers/thumb/elvis.57d4757.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/eloise.112208b.png     1\n",
      "https://villagerdb.com/images/villagers/thumb/elmer.cc7df52.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/ellie.5a144a6.png      1\n",
      "https://villagerdb.com/images/villagers/thumb/zucker.8dbb719.png     1\n",
      "Name: count, Length: 391, dtype: int64\n",
      "==================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "villagers_data = pd.read_csv(url)\n",
    "\n",
    "# Show the first 5 rows of the dataset\n",
    "print(\"First 5 Rows of the Dataset:\")\n",
    "print(\"-\" * 50)\n",
    "print(villagers_data.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Show summary information about the dataset (like number of columns, types, etc.)\n",
    "print(\"Dataset Information:\")\n",
    "print(\"-\" * 50)\n",
    "villagers_data.info()\n",
    "print(\"\\n\")\n",
    "\n",
    "# Display summary statistics for numerical columns\n",
    "print(\"Summary Statistics for Numerical Columns:\")\n",
    "print(\"-\" * 50)\n",
    "print(villagers_data.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Display value counts for each categorical column\n",
    "print(\"Value Counts for Categorical Columns:\")\n",
    "print(\"=\" * 50)\n",
    "for column in villagers_data.columns:\n",
    "    print(f\"\\nColumn: {column}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(villagers_data[column].value_counts())\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae623eca",
   "metadata": {},
   "source": [
    "# QUESTION 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e78da3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values in the DataFrame: 869\n",
      "Missing values per row:\n",
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "886    1\n",
      "887    0\n",
      "888    2\n",
      "889    0\n",
      "890    1\n",
      "Length: 891, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df1 = pd.read_csv(url)\n",
    "\n",
    "# Sum of missing values per column\n",
    "missing_per_column = df1.isna().sum()\n",
    "\n",
    "# Sum of missing values per row\n",
    "missing_per_row = df1.isna().sum(axis=1)\n",
    "\n",
    "# Total number of missing values in the DataFrame\n",
    "total_missing = missing_per_column.sum()\n",
    "print(f\"Total missing values in the DataFrame: {total_missing}\")\n",
    "\n",
    "# Optionally, you can also print the missing values per row\n",
    "print(\"Missing values per row:\")\n",
    "print(missing_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336fe449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \" https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"  # using different csv file with missing values\n",
    "df1 = pd.read_csv(url) \n",
    "df1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a554996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \" https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"  # using different csv file with missing values\n",
    "df1 = pd.read_csv(url) \n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21351d7",
   "metadata": {},
   "source": [
    "## Question 4 Answer\n",
    "this question is about how df1.shape and df1.describe() deals with displaying or calculating missing values.\n",
    "So first of all, df1.shape will give the dimensions of the rows and columns regardless of the type of data, which is good!\n",
    "Secondly, df1.describe() will calculate only numerical values given and will NOT include missing values unless told otherwise which is a discrepancy.\n",
    "\n",
    "Now, the count row represents the number of non-missing values reported by df1.describe() unless told to otherwise which stated before is a discrepancy since it is not an 100% clear accurate representation of the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52ab8a8",
   "metadata": {},
   "source": [
    "## Question 5 DIFFERENCE IN METHOD OR ATTRIBUTE\n",
    "a method does an action of computation and will require parentheses. Example df.describe()\n",
    "\n",
    "an attribute provides information about the data about the object and can be used without parentheses. Example df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a89d30",
   "metadata": {},
   "source": [
    "## Question 6 definition of each analytic in df.describe() \n",
    "#### count: \n",
    "the number of non-missing values in the column\n",
    "#### mean: \n",
    "sum of all the values divided by the count of non-null values, so it it just the average of all values in the column\n",
    "#### standard deviation: \n",
    "it states the deviation of values from the mean. the higher the number calculated the more variability.\n",
    "#### min:\n",
    "the min represents the lowest boundary of the data (lowest number in the dataset)\n",
    "#### 25%:\n",
    " also known as the first quartile, 25% of the data falls below this mark.\n",
    "#### 50%:\n",
    "The median of the data, at this point 50% of the data is below and above this mark\n",
    "#### 75%:\n",
    "the third quartile divides the 75% from the 25% and now 75% of the data falls below this mark\n",
    "#### Max:\n",
    "This represent the highest possible value provided in the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69944f5",
   "metadata": {},
   "source": [
    "# Question 7.1\n",
    "Use case: Cleaning a Dataset with Missing Values in Specific Columns\n",
    "\n",
    "df.dropna() is more useful when you want to drop rows that are missing critical datasets or keep rows missing values of non-critical data. (Also You can use the subset to target specific columns to check for missing values)\n",
    "\n",
    "However, in the case of del df['col'] it will delete an entire column without the same consideration to the data that df.dropna() could give which would not be helpful in our use case of cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785aa34",
   "metadata": {},
   "source": [
    "# Question 7.2\n",
    "Use case: removing an unnecessary column\n",
    "\n",
    "del df['col'] deletes a specified column from the DataFrame, this can be used to delete entire columns that are considered relevant to what you want to analyze.\n",
    "\n",
    "in this case df.dropna() would not be useful because we want to delete a column and not handle missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fefaf8",
   "metadata": {},
   "source": [
    "# Question 7.3\n",
    "using del df['col'] before df.dropna() could be useful in the case of showing better clarity. By cleaning up the DataFrame and dropping column that are no longer useful to what you, you make sure that when you use df.dropna() you are only including relevant data. Which can make your process more easier to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecf1e34",
   "metadata": {},
   "source": [
    "# Question 7.4\n",
    "## Before\n",
    "i'm going to use the titanic DataSet and will first display the before report of the data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e56aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "(891, 15)\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df2 = pd.read_csv(url)\n",
    "\n",
    "# Check the initial shape and missing data\n",
    "print(\"Before cleaning:\")\n",
    "print(df2.shape)\n",
    "print(df2.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9556855e",
   "metadata": {},
   "source": [
    "### Approach\n",
    "i'm goin to remove 'deck' since it is the one with the most missing values using  del df2['col'] and im going to remove rows with missing values with df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c54a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After cleaning:\n",
      "(712, 14)\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df2 = pd.read_csv(url)\n",
    "\n",
    "del df2['deck']\n",
    "\n",
    "# Drop rows with missing values in remaining columns\n",
    "df2_cleaned = df2.dropna()\n",
    "\n",
    "# Check the shape and missing data after cleaning\n",
    "print(\"\\nAfter cleaning:\")\n",
    "print(df2_cleaned.shape)\n",
    "print(df2_cleaned.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8913fcf",
   "metadata": {},
   "source": [
    "### Approach justification\n",
    "deck had the most missing values meaning it had very little value in our data so removing it was necessary, then we used dropna() to remove rows with missing information in important columns.\n",
    "### Before: \n",
    "dataset had 891 rows and 15 columns with missing values in important columns.\n",
    "### After: \n",
    "cleaned dataset now has 712 rows and 14 columns with all missing data removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d9635",
   "metadata": {},
   "source": [
    "## Question 8.1 explaining df.groupby(\"col1\")[\"col2\"].describe()\n",
    "df.groupby(\"col1\") makes different groups of each unique value in col1. \n",
    "\n",
    "Then [\"col2\"].describe() this will make summary statistics for col2 in each group.\n",
    "## EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c56a191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alligator</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>lazy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anteater</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>peppy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bear</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>cranky</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>jock</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bull</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>cranky</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count unique     top freq\n",
       "species                            \n",
       "alligator     7      5    lazy    2\n",
       "anteater      7      6   peppy    2\n",
       "bear         15      7  cranky    5\n",
       "bird         13      7    jock    4\n",
       "bull          6      3  cranky    3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.groupby(\"species\")[\"personality\"].describe().head()  # only displaying top 5, too many rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28171a",
   "metadata": {},
   "source": [
    "## Question 8.2 DIFFERENCE  between  df.describe()   &    df.groupby(\"col1\")[\"col2\"].describe()\n",
    " df.describe() checks independently each column and does not pay attention to the relationship between them like  df.groupby(\"col1\")[\"col2\"].describe() does.\n",
    " \n",
    " df.groupby(\"col1\")[\"col2\"].describe() also gives a more descriptive breakdown. the count calculated is for col2 within each group of col1 and like df.describe() it only counts non-missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407d420",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f0b74",
   "metadata": {},
   "source": [
    "# 8.3 A not importing pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb9ed40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101dca7f",
   "metadata": {},
   "source": [
    "# 8.3A\n",
    "### Chatgpt \n",
    "correctly told me to import pandas as pd in the first line of my code\n",
    "### Google\n",
    "a google search told me to import pandas before using it, but didn't tell me how and it took way more time than chatgpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710d13e7",
   "metadata": {},
   "source": [
    "# 8.3B TYPO titanic => titanics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3078d0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    371\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    373\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanics.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeafd90e",
   "metadata": {},
   "source": [
    "### chatgpt\n",
    "I gave my code to chatgpt and the error code I got it, surprisingly told me that there is a typo in the url and provided the correct link instantly, very impressive.\n",
    "### google\n",
    "after a minute of looking i found that this error is related to invalid http link, but provided no further assistance like chatgpt could"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ea0294",
   "metadata": {},
   "source": [
    "## 8.3C Trying to use a dataframe before it's been assigned into the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21274d2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mDf\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpersonality\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;241m.\u001b[39mhead() \n",
      "\u001b[0;31mNameError\u001b[0m: name 'Df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "Df.groupby(\"species\")[\"personality\"].describe().head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673c677d",
   "metadata": {},
   "source": [
    "### Chatgpt\n",
    "fixed my code and provided code to copy paste to fix my problem\n",
    "\n",
    "### Google\n",
    "google told me how to fix my problem but did not provide specific code like chatgpt did"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f17694a",
   "metadata": {},
   "source": [
    "## 8.4D Forget one parentheses somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48cfd3a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (4205515142.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = pd.read_csv(url\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576b6483",
   "metadata": {},
   "source": [
    "### chatgpt\n",
    "chatgpt gave me code that added the missing parentheses and correctly identified the problem\n",
    "### google\n",
    "google correctly told me that i should carefully scan my code and look for any missing parenthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff34c57",
   "metadata": {},
   "source": [
    "## 8.4E Mistype one of the names of the chained functions with the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a786a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'group_by'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_87/1713471868.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"col2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'group_by'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.group_by(\"col1\")[\"col2\"].describe()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2311f9",
   "metadata": {},
   "source": [
    "### chatgpt \n",
    "chatgpt told me that i mistyped, instead of group_by i should have inputted grouby. not separated by an underscore\n",
    "### google\n",
    "google told me that I miss typed it but couldn't offer specific guidance like chatgpt did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de396cc",
   "metadata": {},
   "source": [
    "## 8.3F column name that's in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c56b6b47",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: sex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspecies\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1964\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1961\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1962\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1963\u001b[0m     )\n\u001b[0;32m-> 1964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: sex'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.groupby(\"species\")[\"sex\"].describe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe7b11",
   "metadata": {},
   "source": [
    "### chatgpt\n",
    "chatgpt told me that 'sex' is not found in my dataframe and my best option would be to use real columns within my dataset\n",
    "### google\n",
    "google essentially told me the same thing that chatgpt did"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a35fb1",
   "metadata": {},
   "source": [
    "## 8.3G Forget to put the column name as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "274a8b66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'species' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[0;32m----> 6\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43mspecies\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpersonality\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'species' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.groupby(species)[\"personality\"].describe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd579bd",
   "metadata": {},
   "source": [
    "### chatgpt\n",
    "chatgpt gave me a code to copy and paste to fix my issue, and correctly identified where the problem was for me\n",
    "\n",
    "### google \n",
    "i typed the error code into google and was told what might be causing this problem, not as useful as chatgpt.\n",
    "\n",
    "# 8.3 SUMMARY\n",
    "google was most definitely way slower than chatgpt and had far more limitations, for example what i would do is i would just copy paste my whole code into chatgpt with my error code and every time it would tell me precisely what my error was and how to fix it. Chatgpt also gave me code to copy and paste to fix my code! Chatgpt is definitely more efficient and precise when it comes to fixing bugs in code than google.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06c1d46",
   "metadata": {},
   "source": [
    "## Question 9 Have you reviewed the course wiki-textbook and interacted with a ChatBot\n",
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f1981",
   "metadata": {},
   "source": [
    "## CHATGPT LINK\n",
    "first half of the homework https://chatgpt.com/share/fa4b951d-780a-446f-a745-b6d9bdf7cf1f\n",
    "\n",
    "second half of the homework https://chatgpt.com/share/c78a428e-7656-42f4-b529-8679d1c3dd7d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
